# GC log 分析
## 环境说明
### GC日志
联想工作站:
CPU：Xeon-E5 8核，
内存：32GB，
OS：Centos8，
JVM：JDK11
### 压力测试
Mac Pro：
CPU：Intel 4核，
内存：8G，
JVM：JDK11
## 操作流程
1. 分别配置VM参数 -Xmx，-Xms为128MB、256MB、512MB、1GB、2GB、4GB、8GB、16GB，GC为 SerialGC、ParallelGC、CMS、G1、ZGC启动GCLogAnalysis.java测试输出gc日志，见gclog目录。
2. 分别配置Xmx,Xms大小为256MB和4GB，GC类型为串行、并行、CMS和G1启动gateway-server.jar程序，进行压力测试：wrk -t8 -c256 -d60s http://127.0.0.1:8088/api/hello
## 分析
1. 在相同GC的情况下：总的来说堆越大发生GC的次数相对越少，单次GC耗时越长；当-Xmx更大时Full GC的概率更小，当堆大小大于2G时甚至有可能只出现Young GC。当堆配置越小会GC越频繁，发生Full GC的概率更高，当堆过小时Full GC十分频繁但GC效率并不高，程序甚至出现OOM。
2. 在相同堆大小规格的配置下：当堆较小时 并行GC 要比 串行GC 和 CMS GC 耗时相对长一些，并行GC > CMS > 穿行GC；G1 发生GC的次数要高于前述三种，ZGC发生OOM。当堆变大时不同的GC耗时均有相应增加，GC次数相应减少，但总的来说并行GC的耗时变化更陡峭，当堆配置超过4G时并行GC的单次耗时要高于其它的几种GC，其GC次数也更少。
3. GC效率：除了堆过小的情况下（各种GC的效率都很频繁但效率普遍不高），并行的回收效率相对较高，耗时也相对较长；虽然G1的耗时更加可控，但是GC回收效率并不高。
4. 在前文的压力测试环境下相同堆大小的情况下，并行GC的吞吐量相对较高，延迟也相对较高，在4GB堆大小的情况下最大延迟高达1.5s完全无法接受；在堆配置为不大即（256MB）的时候各种GC的表现差距并不大。通过相同GC类型不同堆大小的对比总的来说并行GC的差异较大，显得不稳定，而G1不管是在平均还是最大延迟相对来说都更加稳定；本次测试G1的表现并没有显示出其优势，分析除了单次测试的不确定性外另外是受测试环境的限制，毕竟我没有在更大堆（大于4GB）配置下测试。
5. 通过本次压力测试还发现另一个问题，通过相同GC不同堆大小的比较对于gateway-server.jar这样的业务简单的程序增大堆大小无助于程序吞吐量的增加，反而由于堆大小的增加导致单次GC的时间变长，延迟增加。但是G1和CMS的表现在256M-4GB的配置下表现却相对未定。
6. 当服务机和压力机是不同机器时，测试结果受网络的干扰更大；当我通过工作站启动程序，Mac作为压力机测试发现吞吐量维持在2k～3K左右和我在同一机器下的测试结果相差甚大，由于网络环境太差结果不具有参考价值。
7. 当Xmx配置错误时，测试的结果和理论相差甚大；在一开始的时候我错误的将Xmx配置为16GB（我本机只有8G，这并非有意的本来想在工作站完成测试）进行测试，发现压力测试的结果差强人意，特别是G1表现延迟很大不稳定，无法得出结论。
